# Model-Optimized Agent Configuration
# Based on available Ollama models: mistral, qwen2.5-coder:14b, gpt-oss:20b

# === GENERAL SETTINGS ===
OLLAMA_BASE_URL=http://localhost:11434/v1
DEBUG=false
LOG_LEVEL=INFO

# === DEFAULT MODEL ===
# Use mistral for general tasks (fastest)
DEFAULT_MODEL=ollama:mistral
DEFAULT_TEMPERATURE=0.3

# === AGENT-SPECIFIC MODELS ===
# These override the default for specific agents

# Coordinator - needs to be fast and understand intent
COORDINATOR_MODEL=ollama:mistral
COORDINATOR_TEMPERATURE=0.2

# Codebase Investigator - benefits from code-specialized model
CODEBASE_MODEL=ollama:qwen2.5-coder:14b
CODEBASE_TEMPERATURE=0.3

# File Editor - needs precision, use code model
FILE_EDITOR_MODEL=ollama:qwen2.5-coder:14b
FILE_EDITOR_TEMPERATURE=0.1

# Testing Agent - code generation, use specialized model
TESTING_MODEL=ollama:qwen2.5-coder:14b
TESTING_TEMPERATURE=0.2

# Documentation Agent - general writing, mistral is fine
DOCUMENTATION_MODEL=ollama:mistral
DOCUMENTATION_TEMPERATURE=0.5

# Refactoring Agent - complex reasoning, use largest model
REFACTORING_MODEL=ollama:gpt-oss:20b
REFACTORING_TEMPERATURE=0.2

# Code Generator - NEW file creation with code generation
CODE_GENERATOR_MODEL=ollama:qwen2.5-coder:14b
CODE_GENERATOR_TEMPERATURE=0.1

# === OPTIONAL: OPENAI API ===
# Uncomment if you want to use OpenAI models as fallback
# OPENAI_API_KEY=your-api-key-here

# === PERFORMANCE TUNING ===
# Number of retries for failed agent calls
DEFAULT_RETRIES=2

# === NOTES ===
# Model Selection Strategy:
# - mistral (4.4GB): Fast, good for routing and general tasks
# - qwen2.5-coder:14b (9GB): Best for code-related tasks
# - gpt-oss:20b (13GB): Most capable, use sparingly for complex tasks
#
# Temperature Guide:
# - 0.0-0.2: Deterministic, precise (editing, formatting)
# - 0.2-0.4: Focused but creative (code generation, analysis)
# - 0.4-0.6: Balanced creativity (documentation, explanations)
