# Granite3.3-Optimized Agent Configuration
# Granite 3.3 is specifically trained for instruction following and tool use

# === GENERAL SETTINGS ===
OLLAMA_BASE_URL=http://localhost:11434/v1
DEBUG=false
LOG_LEVEL=INFO

# === DEFAULT MODEL ===
# Use granite3.3 as default - excellent instruction following
DEFAULT_MODEL=ollama:granite3.3:8b
DEFAULT_TEMPERATURE=0.3
DEFAULT_RETRIES=2

# === AGENT-SPECIFIC MODELS ===

# Coordinator - needs instruction following for tool routing
COORDINATOR_MODEL=ollama:granite3.3:8b
COORDINATOR_TEMPERATURE=0.2

# Codebase Investigator - use qwen for code understanding
CODEBASE_MODEL=ollama:qwen2.5-coder:14b
CODEBASE_TEMPERATURE=0.3

# File Editor - CRITICAL: Use granite3.3 for tool calling reliability
FILE_EDITOR_MODEL=ollama:granite3.3:8b
FILE_EDITOR_TEMPERATURE=0.1

# Testing Agent - granite for test generation with tool use
TESTING_MODEL=ollama:granite3.3:8b
TESTING_TEMPERATURE=0.2

# Documentation Agent - granite handles structured output well
DOCUMENTATION_MODEL=ollama:granite3.3:8b
DOCUMENTATION_TEMPERATURE=0.5

# Refactoring Agent - use gpt-oss for complex reasoning
REFACTORING_MODEL=ollama:gpt-oss:20b
REFACTORING_TEMPERATURE=0.2

# Code Generator - NEW file creation with code generation
CODE_GENERATOR_MODEL=ollama:qwen2.5-coder:14b
CODE_GENERATOR_TEMPERATURE=0.1

# === WHY GRANITE3.3? ===
#
# Granite 3.3 advantages:
# 1. **Trained for tool calling** - IBM focused on function calling capabilities
# 2. **Instruction following** - Better adherence to system prompts
# 3. **Structured output** - Excels at producing required formats
# 4. **8B parameter size** - Fast while still capable
#
# Model assignments rationale:
# - granite3.3 → Tasks requiring tool calls (coordinator, file_editor, testing, docs)
# - qwen2.5-coder → Pure code analysis (codebase investigator)
# - gpt-oss:20b → Complex refactoring requiring deep reasoning
#
# Expected improvement:
# File editor should now ACTUALLY CALL tools instead of explaining!
