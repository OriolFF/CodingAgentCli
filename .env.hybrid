# Hybrid Configuration: Local Ollama + OpenRouter
# Best of both worlds: Free local coordination, premium code generation

# === GENERAL SETTINGS ===
OLLAMA_BASE_URL=http://localhost:11434/v1
DEBUG=false
LOG_LEVEL=INFO

# === OPENROUTER SETTINGS ===
# Only needed for code generation models
OPENROUTER_API_KEY=your_openrouter_api_key_here
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# === DEFAULT MODEL ===
# Fallback to local Ollama
DEFAULT_MODEL=ollama:llama3.1:8b-instruct-q8_0
DEFAULT_TEMPERATURE=0.3
DEFAULT_RETRIES=2

# === AGENT-SPECIFIC MODELS ===

# Coordinator - FREE local model (tool routing)
COORDINATOR_MODEL=ollama:llama3.1:8b-instruct-q8_0
COORDINATOR_TEMPERATURE=0.0

# File Editor - FREE local model (file operations)
FILE_EDITOR_MODEL=ollama:llama3.1:8b-instruct-q8_0
FILE_EDITOR_TEMPERATURE=0.0

# Code Generator - PAID OpenRouter (premium quality)
# Options: 
#   - deepseek/deepseek-chat (cheaper, faster)
#   - anthropic/claude-3.5-sonnet (best quality)
#   - qwen/qwen-2.5-coder-32b-instruct (excellent for code)
CODE_GENERATOR_MODEL=openai:deepseek/deepseek-chat
CODE_GENERATOR_TEMPERATURE=0.1

# Codebase Investigator - FREE local model (code analysis)
CODEBASE_MODEL=ollama:qwen2.5-coder:14b
CODEBASE_TEMPERATURE=0.0

# Testing Agent - FREE local model
TESTING_MODEL=ollama:llama3.1:8b-instruct-q8_0
TESTING_TEMPERATURE=0.0

# Documentation Agent - FREE local model
DOCUMENTATION_MODEL=ollama:llama3.1:8b-instruct-q8_0
DOCUMENTATION_TEMPERATURE=0.5

# Refactoring Agent - FREE local model
REFACTORING_MODEL=ollama:qwen2.5-coder:14b
REFACTORING_TEMPERATURE=0.0
